{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [1,2,3]\n",
    "y = [1,2,3]\n",
    "\n",
    "W = tf.placeholder(tf.float32)\n",
    "\n",
    "hypothesis = X * W\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y))\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "W_val = []\n",
    "cost_val = []\n",
    "for i in range(-30, 50):\n",
    "    feed_W = i * 0.1\n",
    "    curr_cost, curr_W = sess.run([cost, W], feed_dict={W: feed_W})\n",
    "    W_val.append(curr_W)\n",
    "    cost_val.append(curr_cost)\n",
    "\n",
    "plt.plot(W_val, cost_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.00024100782 [0.9928136]\n",
      "1 6.855302e-05 [0.99616724]\n",
      "2 1.9499486e-05 [0.99795586]\n",
      "3 5.546662e-06 [0.9989098]\n",
      "4 1.5776201e-06 [0.99941856]\n",
      "5 4.4878553e-07 [0.9996899]\n",
      "6 1.2765149e-07 [0.9998346]\n",
      "7 3.6315367e-08 [0.9999118]\n",
      "8 1.03265885e-08 [0.999953]\n",
      "9 2.9415297e-09 [0.9999749]\n",
      "10 8.318845e-10 [0.99998665]\n",
      "11 2.3393554e-10 [0.9999929]\n",
      "12 6.7908935e-11 [0.9999962]\n",
      "13 1.9653612e-11 [0.999998]\n",
      "14 5.6322356e-12 [0.9999989]\n",
      "15 1.4080589e-12 [0.99999946]\n",
      "16 4.5119464e-13 [0.9999997]\n",
      "17 1.2908193e-13 [0.9999998]\n",
      "18 9.947598e-14 [0.9999999]\n",
      "19 2.4868996e-14 [0.99999994]\n",
      "20 0.0 [1.]\n"
     ]
    }
   ],
   "source": [
    "x_data = [1,2,3]\n",
    "y_data = [1,2,3]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]))\n",
    "X = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "hypothesis = X * W\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y))\n",
    "\n",
    "learning_rate = 0.1\n",
    "gradient = tf.reduce_mean((W*X-y)*X)\n",
    "descent = W -learning_rate * gradient\n",
    "update = W.assign(descent)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "W_val = []\n",
    "cost_val = []\n",
    "for step in range(21):\n",
    "    sess.run(update, feed_dict = {X: x_data, y: y_data})\n",
    "    print(step, sess.run(cost, feed_dict = {X: x_data, y: y_data}), sess.run(W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -3.0\n",
      "1 0.73333365\n",
      "2 0.98222226\n",
      "3 0.9988148\n",
      "4 0.99992096\n",
      "5 0.9999947\n",
      "6 0.99999964\n",
      "7 0.99999994\n",
      "8 1.0\n",
      "9 1.0\n",
      "10 1.0\n",
      "11 1.0\n",
      "12 1.0\n",
      "13 1.0\n",
      "14 1.0\n",
      "15 1.0\n",
      "16 1.0\n",
      "17 1.0\n",
      "18 1.0\n",
      "19 1.0\n",
      "20 1.0\n"
     ]
    }
   ],
   "source": [
    "# 더 줄여보자\n",
    "X = [1,2,3]\n",
    "y = [1,2,3]\n",
    "W = tf.Variable(-3.0)\n",
    "\n",
    "hypothesis = X * W\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.1)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "W_val = []\n",
    "cost_val = []\n",
    "for step in range(21):\n",
    "    print(step, sess.run(W))\n",
    "    sess.run(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [-37.333332, -3.0, [(-37.333336, -3.0)]]\n",
      "1 [-33.84889, -2.6266665, [(-33.84889, -2.6266665)]]\n",
      "2 [-30.689661, -2.2881777, [(-30.68966, -2.2881777)]]\n",
      "3 [-27.825293, -1.9812812, [(-27.825293, -1.9812812)]]\n",
      "4 [-25.228264, -1.7030282, [(-25.228264, -1.7030282)]]\n",
      "5 [-22.873625, -1.4507456, [(-22.873627, -1.4507456)]]\n",
      "6 [-20.738754, -1.2220093, [(-20.738754, -1.2220093)]]\n",
      "7 [-18.803137, -1.0146217, [(-18.803137, -1.0146217)]]\n",
      "8 [-17.048178, -0.82659036, [(-17.048176, -0.82659036)]]\n",
      "9 [-15.457013, -0.6561086, [(-15.457014, -0.6561086)]]\n",
      "10 [-14.0143585, -0.50153846, [(-14.0143585, -0.50153846)]]\n",
      "11 [-12.706352, -0.36139488, [(-12.706352, -0.36139488)]]\n",
      "12 [-11.520427, -0.23433137, [(-11.520426, -0.23433137)]]\n",
      "13 [-10.445187, -0.11912712, [(-10.445187, -0.11912712)]]\n",
      "14 [-9.470303, -0.014675253, [(-9.470303, -0.014675253)]]\n",
      "15 [-8.586408, 0.080027774, [(-8.586408, 0.080027774)]]\n",
      "16 [-7.7850094, 0.16589186, [(-7.7850094, 0.16589186)]]\n",
      "17 [-7.0584083, 0.24374194, [(-7.0584087, 0.24374194)]]\n",
      "18 [-6.399624, 0.31432602, [(-6.399624, 0.31432602)]]\n",
      "19 [-5.802326, 0.37832224, [(-5.8023257, 0.37832224)]]\n",
      "20 [-5.260775, 0.4363455, [(-5.2607756, 0.4363455)]]\n",
      "21 [-4.76977, 0.48895323, [(-4.7697697, 0.48895323)]]\n",
      "22 [-4.324591, 0.53665096, [(-4.324591, 0.53665096)]]\n",
      "23 [-3.9209626, 0.57989687, [(-3.9209628, 0.57989687)]]\n",
      "24 [-3.5550063, 0.6191065, [(-3.5550065, 0.6191065)]]\n",
      "25 [-3.2232058, 0.6546565, [(-3.2232058, 0.6546565)]]\n",
      "26 [-2.9223735, 0.6868886, [(-2.9223735, 0.6868886)]]\n",
      "27 [-2.6496184, 0.7161123, [(-2.6496186, 0.7161123)]]\n",
      "28 [-2.4023209, 0.7426085, [(-2.4023209, 0.7426085)]]\n",
      "29 [-2.1781037, 0.7666317, [(-2.1781037, 0.7666317)]]\n",
      "30 [-1.9748144, 0.78841275, [(-1.9748145, 0.78841275)]]\n",
      "31 [-1.7904981, 0.8081609, [(-1.790498, 0.8081609)]]\n",
      "32 [-1.6233851, 0.8260659, [(-1.6233852, 0.8260659)]]\n",
      "33 [-1.4718689, 0.84229976, [(-1.4718688, 0.84229976)]]\n",
      "34 [-1.3344942, 0.8570185, [(-1.3344944, 0.8570185)]]\n",
      "35 [-1.2099415, 0.8703634, [(-1.2099416, 0.8703634)]]\n",
      "36 [-1.0970136, 0.88246286, [(-1.0970136, 0.88246286)]]\n",
      "37 [-0.9946258, 0.893433, [(-0.9946258, 0.893433)]]\n",
      "38 [-0.9017935, 0.90337926, [(-0.9017935, 0.90337926)]]\n",
      "39 [-0.817626, 0.9123972, [(-0.817626, 0.9123972)]]\n",
      "40 [-0.74131423, 0.9205735, [(-0.7413143, 0.9205735)]]\n",
      "41 [-0.67212486, 0.9279866, [(-0.67212486, 0.9279866)]]\n",
      "42 [-0.6093931, 0.9347079, [(-0.6093931, 0.9347079)]]\n",
      "43 [-0.55251664, 0.9408018, [(-0.5525167, 0.9408018)]]\n",
      "44 [-0.50094825, 0.946327, [(-0.5009483, 0.946327)]]\n",
      "45 [-0.4541931, 0.95133644, [(-0.4541931, 0.95133644)]]\n",
      "46 [-0.41180158, 0.9558784, [(-0.41180158, 0.9558784)]]\n",
      "47 [-0.37336704, 0.9599964, [(-0.37336704, 0.9599964)]]\n",
      "48 [-0.3385191, 0.9637301, [(-0.3385191, 0.9637301)]]\n",
      "49 [-0.30692425, 0.9671153, [(-0.30692428, 0.9671153)]]\n",
      "50 [-0.27827808, 0.9701845, [(-0.27827808, 0.9701845)]]\n",
      "51 [-0.25230527, 0.97296727, [(-0.25230527, 0.97296727)]]\n",
      "52 [-0.2287569, 0.97549033, [(-0.2287569, 0.97549033)]]\n",
      "53 [-0.2074064, 0.9777779, [(-0.2074064, 0.9777779)]]\n",
      "54 [-0.18804836, 0.97985196, [(-0.18804836, 0.97985196)]]\n",
      "55 [-0.17049722, 0.9817324, [(-0.17049722, 0.9817324)]]\n",
      "56 [-0.15458433, 0.9834374, [(-0.15458433, 0.9834374)]]\n",
      "57 [-0.14015608, 0.98498327, [(-0.14015608, 0.98498327)]]\n",
      "58 [-0.12707524, 0.9863848, [(-0.12707524, 0.9863848)]]\n",
      "59 [-0.115214705, 0.9876556, [(-0.115214705, 0.9876556)]]\n",
      "60 [-0.10446099, 0.98880774, [(-0.104461, 0.98880774)]]\n",
      "61 [-0.09471134, 0.98985237, [(-0.09471135, 0.98985237)]]\n",
      "62 [-0.08587134, 0.9907995, [(-0.08587134, 0.9907995)]]\n",
      "63 [-0.0778567, 0.9916582, [(-0.077856705, 0.9916582)]]\n",
      "64 [-0.070590414, 0.99243677, [(-0.07059042, 0.99243677)]]\n",
      "65 [-0.06400168, 0.99314266, [(-0.06400168, 0.99314266)]]\n",
      "66 [-0.058028262, 0.9937827, [(-0.058028262, 0.9937827)]]\n",
      "67 [-0.052612025, 0.994363, [(-0.05261203, 0.994363)]]\n",
      "68 [-0.047701597, 0.99488914, [(-0.047701597, 0.99488914)]]\n",
      "69 [-0.04324909, 0.99536616, [(-0.043249093, 0.99536616)]]\n",
      "70 [-0.039212506, 0.99579865, [(-0.039212506, 0.99579865)]]\n",
      "71 [-0.035552662, 0.9961908, [(-0.035552662, 0.9961908)]]\n",
      "72 [-0.03223415, 0.9965463, [(-0.032234155, 0.9965463)]]\n",
      "73 [-0.029225627, 0.99686867, [(-0.029225629, 0.99686867)]]\n",
      "74 [-0.02649816, 0.9971609, [(-0.02649816, 0.9971609)]]\n",
      "75 [-0.024025043, 0.9974259, [(-0.024025043, 0.9974259)]]\n",
      "76 [-0.021782199, 0.9976662, [(-0.0217822, 0.9976662)]]\n",
      "77 [-0.01974968, 0.997884, [(-0.019749682, 0.997884)]]\n",
      "78 [-0.017906507, 0.99808145, [(-0.017906507, 0.99808145)]]\n",
      "79 [-0.016235352, 0.9982605, [(-0.016235352, 0.9982605)]]\n",
      "80 [-0.014719963, 0.99842286, [(-0.014719963, 0.99842286)]]\n",
      "81 [-0.013345639, 0.9985701, [(-0.013345639, 0.9985701)]]\n",
      "82 [-0.01210018, 0.99870354, [(-0.012100181, 0.99870354)]]\n",
      "83 [-0.010971109, 0.99882454, [(-0.010971109, 0.99882454)]]\n",
      "84 [-0.009946823, 0.99893427, [(-0.009946823, 0.99893427)]]\n",
      "85 [-0.009018223, 0.99903375, [(-0.009018223, 0.99903375)]]\n",
      "86 [-0.008176883, 0.99912393, [(-0.008176884, 0.99912393)]]\n",
      "87 [-0.007413149, 0.9992057, [(-0.007413149, 0.9992057)]]\n",
      "88 [-0.006721576, 0.99927986, [(-0.006721576, 0.99927986)]]\n",
      "89 [-0.0060940585, 0.9993471, [(-0.0060940585, 0.9993471)]]\n",
      "90 [-0.005525271, 0.999408, [(-0.0055252714, 0.999408)]]\n",
      "91 [-0.0050096908, 0.99946326, [(-0.005009691, 0.99946326)]]\n",
      "92 [-0.0045423904, 0.9995133, [(-0.004542391, 0.9995133)]]\n",
      "93 [-0.0041182437, 0.99955875, [(-0.004118244, 0.99955875)]]\n",
      "94 [-0.0037339528, 0.99959993, [(-0.003733953, 0.99959993)]]\n",
      "95 [-0.0033854644, 0.99963725, [(-0.0033854644, 0.99963725)]]\n",
      "96 [-0.0030694802, 0.9996711, [(-0.0030694804, 0.9996711)]]\n",
      "97 [-0.0027831, 0.9997018, [(-0.0027831, 0.9997018)]]\n",
      "98 [-0.0025234222, 0.99972963, [(-0.0025234222, 0.99972963)]]\n",
      "99 [-0.0022882223, 0.99975485, [(-0.0022882223, 0.99975485)]]\n"
     ]
    }
   ],
   "source": [
    "# gradient를 수정하고 싶을 때.\n",
    "X = [1,2,3]\n",
    "y = [1,2,3]\n",
    "W = tf.Variable(-3.)\n",
    "\n",
    "hypothesis = X * W\n",
    "\n",
    "gradient = tf.reduce_mean((W*X -y) * X) * 2\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "\n",
    "# train = optimizer.minimize(cost) 의 과정은 이러하다.\n",
    "gvs = optimizer.compute_gradients(cost, [W]) # gvs를 바꿔주면 된다.\n",
    "apply_gradients = optimizer.apply_gradients(gvs)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(100):\n",
    "    print(step, sess.run([gradient, W, gvs]))\n",
    "    sess.run(apply_gradients)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow (GPU)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
