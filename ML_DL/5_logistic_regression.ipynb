{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.8471935\n",
      "200 0.5486577\n",
      "400 0.46410218\n",
      "600 0.42303887\n",
      "800 0.39815328\n",
      "1000 0.38020292\n",
      "1200 0.36566436\n",
      "1400 0.35303688\n",
      "1600 0.3416213\n",
      "1800 0.33106598\n",
      "2000 0.32118145\n",
      "2200 0.31185713\n",
      "2400 0.30302355\n",
      "2600 0.29463273\n",
      "2800 0.28664875\n",
      "3000 0.27904296\n",
      "3200 0.2717907\n",
      "3400 0.26487026\n",
      "3600 0.25826183\n",
      "3800 0.25194743\n",
      "4000 0.2459101\n",
      "4200 0.24013428\n",
      "4400 0.23460513\n",
      "4600 0.22930902\n",
      "4800 0.22423299\n",
      "5000 0.21936488\n",
      "5200 0.21469337\n",
      "5400 0.21020786\n",
      "5600 0.20589845\n",
      "5800 0.2017557\n",
      "6000 0.19777079\n",
      "6200 0.19393553\n",
      "6400 0.19024225\n",
      "6600 0.18668355\n",
      "6800 0.18325283\n",
      "7000 0.17994352\n",
      "7200 0.17674972\n",
      "7400 0.17366575\n",
      "7600 0.17068632\n",
      "7800 0.16780649\n",
      "8000 0.16502143\n",
      "8200 0.16232683\n",
      "8400 0.15971845\n",
      "8600 0.1571924\n",
      "8800 0.15474497\n",
      "9000 0.15237267\n",
      "9200 0.15007216\n",
      "9400 0.14784032\n",
      "9600 0.14567424\n",
      "9800 0.14357106\n",
      "10000 0.14152826\n",
      "\n",
      "Hypothesis:  [[0.02746148]\n",
      " [0.15415137]\n",
      " [0.2887706 ]\n",
      " [0.78883487]\n",
      " [0.9441744 ]\n",
      " [0.98172325]] \n",
      "Correct (Y):  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      "Accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "x_data = [[1, 2],\n",
    "          [2, 3],\n",
    "          [3, 1],\n",
    "          [4, 3],\n",
    "          [5, 3],\n",
    "          [6, 2]]\n",
    "y_data = [[0],\n",
    "          [0],\n",
    "          [0],\n",
    "          [1],\n",
    "          [1],\n",
    "          [1]]\n",
    "X = tf.placeholder(tf.float32, shape=[None,2])\n",
    "Y = tf.placeholder(tf.float32, shape=[None,1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([2,1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1], name='bias'))\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "        cost_val, _ = sess.run([cost, train], feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 200 == 0:\n",
    "            print(step, cost_val)\n",
    "            \n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect (Y): \", c, \"\\nAccuracy\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.66040725\n",
      "200 0.60235876\n",
      "400 0.58126545\n",
      "600 0.56947696\n",
      "800 0.56037664\n",
      "1000 0.5525732\n",
      "1200 0.5457086\n",
      "1400 0.5396255\n",
      "1600 0.5342153\n",
      "1800 0.52938896\n",
      "2000 0.5250712\n",
      "[[0.5035887 ]\n",
      " [0.8106758 ]\n",
      " [0.26559886]\n",
      " [0.92186964]\n",
      " [0.3630488 ]\n",
      " [0.69214433]\n",
      " [0.87943196]\n",
      " [0.5573875 ]\n",
      " [0.31158334]\n",
      " [0.7197486 ]\n",
      " [0.7291772 ]\n",
      " [0.2935867 ]\n",
      " [0.54282874]\n",
      " [0.18438672]\n",
      " [0.68891203]\n",
      " [0.6588634 ]\n",
      " [0.6945768 ]\n",
      " [0.79724234]\n",
      " [0.8068933 ]\n",
      " [0.68876296]\n",
      " [0.7776241 ]\n",
      " [0.26368198]\n",
      " [0.58361393]\n",
      " [0.7066041 ]\n",
      " [0.5039673 ]\n",
      " [0.8284383 ]\n",
      " [0.678762  ]\n",
      " [0.7183697 ]\n",
      " [0.7428381 ]\n",
      " [0.5013584 ]\n",
      " [0.8542469 ]\n",
      " [0.8200942 ]\n",
      " [0.5992313 ]\n",
      " [0.78273624]\n",
      " [0.4681428 ]\n",
      " [0.69578755]\n",
      " [0.75115204]\n",
      " [0.8017951 ]\n",
      " [0.4491744 ]\n",
      " [0.53957456]\n",
      " [0.76610225]\n",
      " [0.46911693]\n",
      " [0.44089204]\n",
      " [0.13848197]\n",
      " [0.5080637 ]\n",
      " [0.8130228 ]\n",
      " [0.6228586 ]\n",
      " [0.6292958 ]\n",
      " [0.8508907 ]\n",
      " [0.8338807 ]\n",
      " [0.8819276 ]\n",
      " [0.4782573 ]\n",
      " [0.47579077]\n",
      " [0.8648214 ]\n",
      " [0.3162229 ]\n",
      " [0.79435754]\n",
      " [0.39585027]\n",
      " [0.7130234 ]\n",
      " [0.8587471 ]\n",
      " [0.5627541 ]\n",
      " [0.9085607 ]\n",
      " [0.6431509 ]\n",
      " [0.6761642 ]\n",
      " [0.7263477 ]\n",
      " [0.6387244 ]\n",
      " [0.78804755]\n",
      " [0.8801569 ]\n",
      " [0.6827106 ]\n",
      " [0.8097053 ]\n",
      " [0.6341407 ]\n",
      " [0.5167574 ]\n",
      " [0.62581617]\n",
      " [0.805066  ]\n",
      " [0.6907234 ]\n",
      " [0.87580013]\n",
      " [0.69305366]\n",
      " [0.4373866 ]\n",
      " [0.6558188 ]\n",
      " [0.5788046 ]\n",
      " [0.82480454]\n",
      " [0.87627894]\n",
      " [0.6247622 ]\n",
      " [0.6044785 ]\n",
      " [0.79230416]\n",
      " [0.65678954]\n",
      " [0.8288443 ]\n",
      " [0.5834001 ]\n",
      " [0.6958792 ]\n",
      " [0.89532816]\n",
      " [0.7222415 ]\n",
      " [0.8947657 ]\n",
      " [0.7339991 ]\n",
      " [0.78711736]\n",
      " [0.59860665]\n",
      " [0.7387967 ]\n",
      " [0.90343064]\n",
      " [0.81112343]\n",
      " [0.7607638 ]\n",
      " [0.38982818]\n",
      " [0.4998117 ]\n",
      " [0.73676944]\n",
      " [0.90738183]\n",
      " [0.75152534]\n",
      " [0.78249836]\n",
      " [0.8782084 ]\n",
      " [0.6469677 ]\n",
      " [0.88200396]\n",
      " [0.8222362 ]\n",
      " [0.4968089 ]\n",
      " [0.33980703]\n",
      " [0.90193605]\n",
      " [0.79513717]\n",
      " [0.47826034]\n",
      " [0.68389523]\n",
      " [0.65416604]\n",
      " [0.73915476]\n",
      " [0.66207784]\n",
      " [0.904939  ]\n",
      " [0.4234899 ]\n",
      " [0.5991807 ]\n",
      " [0.8115847 ]\n",
      " [0.77163976]\n",
      " [0.5986758 ]\n",
      " [0.7841467 ]\n",
      " [0.72162676]\n",
      " [0.77394986]\n",
      " [0.8298406 ]\n",
      " [0.79126173]\n",
      " [0.45078647]\n",
      " [0.48029342]\n",
      " [0.45098016]\n",
      " [0.7424388 ]\n",
      " [0.85932344]\n",
      " [0.726849  ]\n",
      " [0.85261405]\n",
      " [0.7729172 ]\n",
      " [0.5278504 ]\n",
      " [0.70592815]\n",
      " [0.7729204 ]\n",
      " [0.69871426]\n",
      " [0.78501225]\n",
      " [0.66441375]\n",
      " [0.45516258]\n",
      " [0.69795245]\n",
      " [0.8734002 ]\n",
      " [0.79516244]\n",
      " [0.6615824 ]\n",
      " [0.75331396]\n",
      " [0.68329096]\n",
      " [0.72166765]\n",
      " [0.5075242 ]\n",
      " [0.4026298 ]\n",
      " [0.26117903]\n",
      " [0.414079  ]\n",
      " [0.8702524 ]\n",
      " [0.7615394 ]\n",
      " [0.8809775 ]\n",
      " [0.3837047 ]\n",
      " [0.54417014]\n",
      " [0.8496094 ]\n",
      " [0.62954324]\n",
      " [0.78606886]\n",
      " [0.54588085]\n",
      " [0.7936954 ]\n",
      " [0.41714147]\n",
      " [0.6435807 ]\n",
      " [0.6746448 ]\n",
      " [0.82287896]\n",
      " [0.7626768 ]\n",
      " [0.6191171 ]\n",
      " [0.7272658 ]\n",
      " [0.8793645 ]\n",
      " [0.91523576]\n",
      " [0.4179601 ]\n",
      " [0.825076  ]\n",
      " [0.6268392 ]\n",
      " [0.5622915 ]\n",
      " [0.5685993 ]\n",
      " [0.8259524 ]\n",
      " [0.6207807 ]\n",
      " [0.9185565 ]\n",
      " [0.8218622 ]\n",
      " [0.61279804]\n",
      " [0.19760436]\n",
      " [0.31133896]\n",
      " [0.80848247]\n",
      " [0.7819933 ]\n",
      " [0.647723  ]\n",
      " [0.79889375]\n",
      " [0.7480945 ]\n",
      " [0.4096696 ]\n",
      " [0.38340318]\n",
      " [0.7554083 ]\n",
      " [0.52504593]\n",
      " [0.8260259 ]\n",
      " [0.794611  ]\n",
      " [0.7698541 ]\n",
      " [0.49666628]\n",
      " [0.6322281 ]\n",
      " [0.5914745 ]\n",
      " [0.57511723]\n",
      " [0.8749236 ]\n",
      " [0.83630097]\n",
      " [0.65336096]\n",
      " [0.31349403]\n",
      " [0.57699364]\n",
      " [0.9025306 ]\n",
      " [0.2966253 ]\n",
      " [0.7772884 ]\n",
      " [0.40390342]\n",
      " [0.4411608 ]\n",
      " [0.4982273 ]\n",
      " [0.75078595]\n",
      " [0.39089668]\n",
      " [0.7511725 ]\n",
      " [0.7135907 ]\n",
      " [0.72269714]\n",
      " [0.6910421 ]\n",
      " [0.23087442]\n",
      " [0.65092766]\n",
      " [0.65073055]\n",
      " [0.67905027]\n",
      " [0.84796715]\n",
      " [0.8990388 ]\n",
      " [0.66899985]\n",
      " [0.304927  ]\n",
      " [0.07269112]\n",
      " [0.715727  ]\n",
      " [0.46108216]\n",
      " [0.59177715]\n",
      " [0.91457397]\n",
      " [0.611682  ]\n",
      " [0.9065978 ]\n",
      " [0.3079324 ]\n",
      " [0.19734198]\n",
      " [0.29524624]\n",
      " [0.6967095 ]\n",
      " [0.8360662 ]\n",
      " [0.84178644]\n",
      " [0.5063303 ]\n",
      " [0.6218195 ]\n",
      " [0.6222521 ]\n",
      " [0.243336  ]\n",
      " [0.5982852 ]\n",
      " [0.15491514]\n",
      " [0.5352172 ]\n",
      " [0.69984186]\n",
      " [0.65491855]\n",
      " [0.6665364 ]\n",
      " [0.88860416]\n",
      " [0.6849683 ]\n",
      " [0.6951436 ]\n",
      " [0.7437305 ]\n",
      " [0.64695984]\n",
      " [0.65435386]\n",
      " [0.2149486 ]\n",
      " [0.391606  ]\n",
      " [0.49248573]\n",
      " [0.69377655]\n",
      " [0.6510785 ]\n",
      " [0.6409013 ]\n",
      " [0.8444216 ]\n",
      " [0.37813333]\n",
      " [0.49311715]\n",
      " [0.6863258 ]\n",
      " [0.53177905]\n",
      " [0.59839344]\n",
      " [0.8972845 ]\n",
      " [0.74163693]\n",
      " [0.959766  ]\n",
      " [0.67671514]\n",
      " [0.8466231 ]\n",
      " [0.62037134]\n",
      " [0.7318222 ]\n",
      " [0.7704028 ]\n",
      " [0.6734288 ]\n",
      " [0.404041  ]\n",
      " [0.67136437]\n",
      " [0.68413323]\n",
      " [0.513017  ]\n",
      " [0.83211434]\n",
      " [0.36838138]\n",
      " [0.72654605]\n",
      " [0.8441816 ]\n",
      " [0.8292053 ]\n",
      " [0.9179319 ]\n",
      " [0.70715773]\n",
      " [0.66029114]\n",
      " [0.6360162 ]\n",
      " [0.5115594 ]\n",
      " [0.5147963 ]\n",
      " [0.5615271 ]\n",
      " [0.6202553 ]\n",
      " [0.7381597 ]\n",
      " [0.7425543 ]\n",
      " [0.27783328]\n",
      " [0.620675  ]\n",
      " [0.92384076]\n",
      " [0.64199024]\n",
      " [0.6001194 ]\n",
      " [0.7864508 ]\n",
      " [0.5414955 ]\n",
      " [0.6931121 ]\n",
      " [0.5154074 ]\n",
      " [0.6844501 ]\n",
      " [0.8115894 ]\n",
      " [0.69281644]\n",
      " [0.6172017 ]\n",
      " [0.71783423]\n",
      " [0.6349265 ]\n",
      " [0.7872075 ]\n",
      " [0.87572753]\n",
      " [0.34002414]\n",
      " [0.7711033 ]\n",
      " [0.41323334]\n",
      " [0.61477375]\n",
      " [0.6615066 ]\n",
      " [0.5472806 ]\n",
      " [0.62456656]\n",
      " [0.7657558 ]\n",
      " [0.59685   ]\n",
      " [0.7317824 ]\n",
      " [0.27606452]\n",
      " [0.8288128 ]\n",
      " [0.84376186]\n",
      " [0.568984  ]\n",
      " [0.86462635]\n",
      " [0.35583037]\n",
      " [0.72294796]\n",
      " [0.86125606]\n",
      " [0.355023  ]\n",
      " [0.5885111 ]\n",
      " [0.726743  ]\n",
      " [0.49303088]\n",
      " [0.3415759 ]\n",
      " [0.7125695 ]\n",
      " [0.88741875]\n",
      " [0.7190288 ]\n",
      " [0.66320854]\n",
      " [0.78584284]\n",
      " [0.7768659 ]\n",
      " [0.6166914 ]\n",
      " [0.67183757]\n",
      " [0.8462741 ]\n",
      " [0.71551734]\n",
      " [0.76188385]\n",
      " [0.5990704 ]\n",
      " [0.8991834 ]\n",
      " [0.8621359 ]\n",
      " [0.82587624]\n",
      " [0.46410784]\n",
      " [0.68093413]\n",
      " [0.41240296]\n",
      " [0.8678599 ]\n",
      " [0.31274033]\n",
      " [0.26213467]\n",
      " [0.59335536]\n",
      " [0.8482462 ]\n",
      " [0.65225875]\n",
      " [0.5188422 ]\n",
      " [0.7971054 ]\n",
      " [0.61126184]\n",
      " [0.7300564 ]\n",
      " [0.8966358 ]\n",
      " [0.8294705 ]\n",
      " [0.23172495]\n",
      " [0.6942237 ]\n",
      " [0.871198  ]\n",
      " [0.8190653 ]\n",
      " [0.6944296 ]\n",
      " [0.5720253 ]\n",
      " [0.8003782 ]\n",
      " [0.8625898 ]\n",
      " [0.41400713]\n",
      " [0.83857906]\n",
      " [0.81644344]\n",
      " [0.61677516]\n",
      " [0.81187236]\n",
      " [0.8465004 ]\n",
      " [0.77760947]\n",
      " [0.7841112 ]\n",
      " [0.62017494]\n",
      " [0.72784936]\n",
      " [0.67457527]\n",
      " [0.80993557]\n",
      " [0.8498619 ]\n",
      " [0.3319245 ]\n",
      " [0.6710755 ]\n",
      " [0.8057437 ]\n",
      " [0.42896014]\n",
      " [0.55081236]\n",
      " [0.8520391 ]\n",
      " [0.45270786]\n",
      " [0.82885224]\n",
      " [0.22802791]\n",
      " [0.7619053 ]\n",
      " [0.74669206]\n",
      " [0.80075747]\n",
      " [0.41625306]\n",
      " [0.6454677 ]\n",
      " [0.74394524]\n",
      " [0.6756625 ]\n",
      " [0.21641895]\n",
      " [0.2587038 ]\n",
      " [0.6882956 ]\n",
      " [0.76969594]\n",
      " [0.48304233]\n",
      " [0.8063617 ]\n",
      " [0.64047396]\n",
      " [0.3075023 ]\n",
      " [0.68080485]\n",
      " [0.50083125]\n",
      " [0.8428789 ]\n",
      " [0.73696893]\n",
      " [0.7618978 ]\n",
      " [0.9035836 ]\n",
      " [0.8353619 ]\n",
      " [0.7167163 ]\n",
      " [0.49210155]\n",
      " [0.3704813 ]\n",
      " [0.67048395]\n",
      " [0.4729205 ]\n",
      " [0.65399426]\n",
      " [0.88432723]\n",
      " [0.7683183 ]\n",
      " [0.8806785 ]\n",
      " [0.8867427 ]\n",
      " [0.6203241 ]\n",
      " [0.74874306]\n",
      " [0.40455356]\n",
      " [0.45154652]\n",
      " [0.49046585]\n",
      " [0.8419178 ]\n",
      " [0.6841689 ]\n",
      " [0.28080648]\n",
      " [0.8750529 ]\n",
      " [0.73426634]\n",
      " [0.62782264]\n",
      " [0.5737013 ]\n",
      " [0.2698007 ]\n",
      " [0.8496354 ]\n",
      " [0.82501125]\n",
      " [0.75273186]\n",
      " [0.7082918 ]\n",
      " [0.88540727]\n",
      " [0.57018656]\n",
      " [0.7407276 ]\n",
      " [0.8172336 ]\n",
      " [0.7877955 ]\n",
      " [0.20884806]\n",
      " [0.7063042 ]\n",
      " [0.85960823]\n",
      " [0.8478706 ]\n",
      " [0.78986204]\n",
      " [0.8660643 ]\n",
      " [0.89642346]\n",
      " [0.7996512 ]\n",
      " [0.65161234]\n",
      " [0.7381971 ]\n",
      " [0.83972144]\n",
      " [0.7602843 ]\n",
      " [0.61876583]\n",
      " [0.50798136]\n",
      " [0.5083484 ]\n",
      " [0.43181482]\n",
      " [0.46860665]\n",
      " [0.66720986]\n",
      " [0.6625428 ]\n",
      " [0.6297996 ]\n",
      " [0.81821245]\n",
      " [0.7628296 ]\n",
      " [0.7818453 ]\n",
      " [0.7286957 ]\n",
      " [0.47765192]\n",
      " [0.572909  ]\n",
      " [0.8728988 ]\n",
      " [0.8268294 ]\n",
      " [0.3574098 ]\n",
      " [0.50391483]\n",
      " [0.5684534 ]\n",
      " [0.37503618]\n",
      " [0.70912516]\n",
      " [0.38461882]\n",
      " [0.86604816]\n",
      " [0.83961105]\n",
      " [0.7398269 ]\n",
      " [0.73478657]\n",
      " [0.79142195]\n",
      " [0.5641837 ]\n",
      " [0.70085746]\n",
      " [0.8805922 ]\n",
      " [0.46919817]\n",
      " [0.553509  ]\n",
      " [0.8858994 ]\n",
      " [0.7738904 ]\n",
      " [0.69348717]\n",
      " [0.8296458 ]\n",
      " [0.78767014]\n",
      " [0.8154675 ]\n",
      " [0.44598645]\n",
      " [0.76337785]\n",
      " [0.8944309 ]\n",
      " [0.7594773 ]\n",
      " [0.7506097 ]\n",
      " [0.6501798 ]\n",
      " [0.8306965 ]\n",
      " [0.76262486]\n",
      " [0.82268065]\n",
      " [0.54204226]\n",
      " [0.6694883 ]\n",
      " [0.75835764]\n",
      " [0.7360234 ]\n",
      " [0.93195635]\n",
      " [0.7552148 ]\n",
      " [0.6135319 ]\n",
      " [0.55434   ]\n",
      " [0.594698  ]\n",
      " [0.8252417 ]\n",
      " [0.9160797 ]\n",
      " [0.7825992 ]\n",
      " [0.6363431 ]\n",
      " [0.62666017]\n",
      " [0.69645566]\n",
      " [0.5597971 ]\n",
      " [0.8824815 ]\n",
      " [0.73829305]\n",
      " [0.8694495 ]\n",
      " [0.5283514 ]\n",
      " [0.7724321 ]\n",
      " [0.91306543]\n",
      " [0.578969  ]\n",
      " [0.74751186]\n",
      " [0.7788132 ]\n",
      " [0.6717249 ]\n",
      " [0.7655303 ]\n",
      " [0.88624024]\n",
      " [0.8982112 ]\n",
      " [0.3742533 ]\n",
      " [0.368551  ]\n",
      " [0.6646961 ]\n",
      " [0.74174744]\n",
      " [0.3556214 ]\n",
      " [0.76775855]\n",
      " [0.86357486]\n",
      " [0.8239953 ]\n",
      " [0.8763508 ]\n",
      " [0.8650795 ]\n",
      " [0.7209039 ]\n",
      " [0.75991297]\n",
      " [0.77610236]\n",
      " [0.6189075 ]\n",
      " [0.7520213 ]\n",
      " [0.71044344]\n",
      " [0.1844798 ]\n",
      " [0.8750896 ]\n",
      " [0.8189429 ]\n",
      " [0.71591014]\n",
      " [0.806562  ]\n",
      " [0.90889126]\n",
      " [0.87184024]\n",
      " [0.62722254]\n",
      " [0.6773661 ]\n",
      " [0.85446364]\n",
      " [0.789818  ]\n",
      " [0.7907339 ]\n",
      " [0.79989105]\n",
      " [0.55886745]\n",
      " [0.7737915 ]\n",
      " [0.7308714 ]\n",
      " [0.7269415 ]\n",
      " [0.5338118 ]\n",
      " [0.48034063]\n",
      " [0.50332826]\n",
      " [0.6285463 ]\n",
      " [0.6414332 ]\n",
      " [0.7319623 ]\n",
      " [0.5146143 ]\n",
      " [0.71278256]\n",
      " [0.50377256]\n",
      " [0.72011846]\n",
      " [0.5409268 ]\n",
      " [0.7949219 ]\n",
      " [0.571607  ]\n",
      " [0.81062645]\n",
      " [0.66785693]\n",
      " [0.8101415 ]\n",
      " [0.68415445]\n",
      " [0.25689992]\n",
      " [0.8412491 ]\n",
      " [0.88814074]\n",
      " [0.44913888]\n",
      " [0.7686243 ]\n",
      " [0.7167475 ]\n",
      " [0.7423591 ]\n",
      " [0.681881  ]\n",
      " [0.6523819 ]\n",
      " [0.33699718]\n",
      " [0.67460585]\n",
      " [0.31443128]\n",
      " [0.88850814]\n",
      " [0.4494644 ]\n",
      " [0.77107966]\n",
      " [0.7512602 ]\n",
      " [0.41822466]\n",
      " [0.41532645]\n",
      " [0.6205793 ]\n",
      " [0.6192797 ]\n",
      " [0.74594784]\n",
      " [0.71195185]\n",
      " [0.9254133 ]\n",
      " [0.6302799 ]\n",
      " [0.5473406 ]\n",
      " [0.8160262 ]\n",
      " [0.7041014 ]\n",
      " [0.29688165]\n",
      " [0.8332107 ]\n",
      " [0.8005332 ]\n",
      " [0.8960903 ]\n",
      " [0.67506945]\n",
      " [0.62176543]\n",
      " [0.6788738 ]\n",
      " [0.8105116 ]\n",
      " [0.62833226]\n",
      " [0.7957523 ]\n",
      " [0.6882979 ]\n",
      " [0.730852  ]\n",
      " [0.7172484 ]\n",
      " [0.63054585]\n",
      " [0.7970124 ]\n",
      " [0.84666544]\n",
      " [0.79251224]\n",
      " [0.8853713 ]\n",
      " [0.7724849 ]\n",
      " [0.5711258 ]\n",
      " [0.60621524]\n",
      " [0.76565343]\n",
      " [0.80643076]\n",
      " [0.43102744]\n",
      " [0.5801338 ]\n",
      " [0.27575776]\n",
      " [0.69043124]\n",
      " [0.5793439 ]\n",
      " [0.86076236]\n",
      " [0.7582222 ]\n",
      " [0.76442516]\n",
      " [0.6378354 ]\n",
      " [0.81047887]\n",
      " [0.29734918]\n",
      " [0.85124445]\n",
      " [0.7771829 ]\n",
      " [0.87729317]\n",
      " [0.49745232]\n",
      " [0.17162012]\n",
      " [0.5685896 ]\n",
      " [0.6183879 ]\n",
      " [0.6412015 ]\n",
      " [0.8287019 ]\n",
      " [0.6586179 ]\n",
      " [0.6331745 ]\n",
      " [0.8055649 ]\n",
      " [0.63096225]\n",
      " [0.5226047 ]\n",
      " [0.7748638 ]\n",
      " [0.9333614 ]\n",
      " [0.6180464 ]\n",
      " [0.8430575 ]\n",
      " [0.24158645]\n",
      " [0.555005  ]\n",
      " [0.66640115]\n",
      " [0.5903557 ]\n",
      " [0.7387141 ]\n",
      " [0.93557376]\n",
      " [0.2622445 ]\n",
      " [0.74929905]\n",
      " [0.6165048 ]\n",
      " [0.71327347]\n",
      " [0.66570365]\n",
      " [0.5960824 ]\n",
      " [0.66979426]\n",
      " [0.6483777 ]\n",
      " [0.7256671 ]\n",
      " [0.6871706 ]\n",
      " [0.43613756]\n",
      " [0.71391344]\n",
      " [0.7273171 ]\n",
      " [0.7990382 ]\n",
      " [0.52534825]\n",
      " [0.5301918 ]\n",
      " [0.6649632 ]\n",
      " [0.68271464]\n",
      " [0.5521125 ]\n",
      " [0.7084519 ]\n",
      " [0.656117  ]\n",
      " [0.4825218 ]\n",
      " [0.63283   ]\n",
      " [0.80879134]\n",
      " [0.7731455 ]\n",
      " [0.5602305 ]\n",
      " [0.5386052 ]\n",
      " [0.4278403 ]\n",
      " [0.8024921 ]\n",
      " [0.36653724]\n",
      " [0.8043797 ]\n",
      " [0.4500177 ]\n",
      " [0.60312855]\n",
      " [0.7757124 ]\n",
      " [0.19312438]\n",
      " [0.4608194 ]\n",
      " [0.7511772 ]\n",
      " [0.78620785]\n",
      " [0.77747935]\n",
      " [0.8091022 ]\n",
      " [0.82960886]\n",
      " [0.71077794]\n",
      " [0.8115678 ]\n",
      " [0.8191422 ]\n",
      " [0.6967711 ]\n",
      " [0.7578666 ]\n",
      " [0.40462333]\n",
      " [0.4241942 ]\n",
      " [0.75164366]\n",
      " [0.7734009 ]\n",
      " [0.6089448 ]\n",
      " [0.47559136]\n",
      " [0.76487094]\n",
      " [0.8337261 ]\n",
      " [0.69634354]\n",
      " [0.7798057 ]\n",
      " [0.81903046]\n",
      " [0.8458299 ]\n",
      " [0.79224956]\n",
      " [0.6945351 ]\n",
      " [0.7758929 ]\n",
      " [0.78561056]\n",
      " [0.55888295]\n",
      " [0.455498  ]\n",
      " [0.82610977]\n",
      " [0.5036773 ]\n",
      " [0.8864045 ]\n",
      " [0.37330472]\n",
      " [0.5015705 ]\n",
      " [0.46942353]\n",
      " [0.8073383 ]\n",
      " [0.66220725]\n",
      " [0.20991474]\n",
      " [0.44254917]\n",
      " [0.78210133]\n",
      " [0.57788354]\n",
      " [0.6522449 ]\n",
      " [0.73792404]\n",
      " [0.44205806]\n",
      " [0.86379886]\n",
      " [0.28671232]\n",
      " [0.7612515 ]\n",
      " [0.86883   ]\n",
      " [0.5885917 ]\n",
      " [0.7594683 ]\n",
      " [0.7107566 ]\n",
      " [0.75670594]] [[1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] 0.74044794\n"
     ]
    }
   ],
   "source": [
    "# 실제 데이터를 써보자 - 당뇨\n",
    "\n",
    "xy = np.loadtxt('data-03-diabetes.csv', delimiter=',', dtype=np.float32)\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 8])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([8, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1], name='bias'))\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(X,W) + b)\n",
    "\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val,_ = sess.run([cost, train], feed_dict={X:x_data, Y:y_data})\n",
    "\n",
    "    if step % 200 == 0:\n",
    "        print(step, cost_val)\n",
    "    \n",
    "h, p, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X:x_data, Y:y_data})\n",
    "print(h,p,a)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Expect 8 fields but have 9 in record 0\n",
      "\t [[Node: DecodeCSV = DecodeCSV[OUT_TYPE=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], field_delim=\",\", na_value=\"\", select_cols=[], use_quote_delim=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ReaderReadV2:1, DecodeCSV/record_defaults_0, DecodeCSV/record_defaults_0, DecodeCSV/record_defaults_0, DecodeCSV/record_defaults_0, DecodeCSV/record_defaults_0, DecodeCSV/record_defaults_0, DecodeCSV/record_defaults_0, DecodeCSV/record_defaults_0)]]\n",
      "\t [[Node: DecodeCSV/_15 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_15_DecodeCSV\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n"
     ]
    },
    {
     "ename": "OutOfRangeError",
     "evalue": "FIFOQueue '_133_batch_8/fifo_queue' is closed and has insufficient elements (requested 4, current size 0)\n\t [[Node: batch_8 = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](batch_8/fifo_queue, batch_8/n)]]\n\nCaused by op 'batch_8', defined at:\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\asyncio\\base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\asyncio\\base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\asyncio\\events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-39-ba463f4ebad2>\", line 11, in <module>\n    train_x_batch, train_y_batch = tf.train.batch([xy[0:-1], xy[-1:]], batch_size=4)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\training\\input.py\", line 988, in batch\n    name=name)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\training\\input.py\", line 762, in _batch\n    dequeued = queue.dequeue_many(batch_size, name=name)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\data_flow_ops.py\", line 483, in dequeue_many\n    self._queue_ref, n=n, component_types=self._dtypes, name=name)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_data_flow_ops.py\", line 3799, in queue_dequeue_many_v2\n    component_types=component_types, timeout_ms=timeout_ms, name=name)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nOutOfRangeError (see above for traceback): FIFOQueue '_133_batch_8/fifo_queue' is closed and has insufficient elements (requested 4, current size 0)\n\t [[Node: batch_8 = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](batch_8/fifo_queue, batch_8/n)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOutOfRangeError\u001b[0m: FIFOQueue '_133_batch_8/fifo_queue' is closed and has insufficient elements (requested 4, current size 0)\n\t [[Node: batch_8 = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](batch_8/fifo_queue, batch_8/n)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-ba463f4ebad2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_x_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y_batch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[0mcost_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my_batch\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1335\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOutOfRangeError\u001b[0m: FIFOQueue '_133_batch_8/fifo_queue' is closed and has insufficient elements (requested 4, current size 0)\n\t [[Node: batch_8 = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](batch_8/fifo_queue, batch_8/n)]]\n\nCaused by op 'batch_8', defined at:\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\asyncio\\base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\asyncio\\base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\asyncio\\events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-39-ba463f4ebad2>\", line 11, in <module>\n    train_x_batch, train_y_batch = tf.train.batch([xy[0:-1], xy[-1:]], batch_size=4)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\training\\input.py\", line 988, in batch\n    name=name)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\training\\input.py\", line 762, in _batch\n    dequeued = queue.dequeue_many(batch_size, name=name)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\data_flow_ops.py\", line 483, in dequeue_many\n    self._queue_ref, n=n, component_types=self._dtypes, name=name)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_data_flow_ops.py\", line 3799, in queue_dequeue_many_v2\n    component_types=component_types, timeout_ms=timeout_ms, name=name)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nOutOfRangeError (see above for traceback): FIFOQueue '_133_batch_8/fifo_queue' is closed and has insufficient elements (requested 4, current size 0)\n\t [[Node: batch_8 = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](batch_8/fifo_queue, batch_8/n)]]\n"
     ]
    }
   ],
   "source": [
    "# 실제 데이터를 써보자 - 당뇨\n",
    "filename_queue = tf.train.string_input_producer(\n",
    "    ['data-03-diabetes.csv'], shuffle=False, name='filename_queue')\n",
    "\n",
    "reader = tf.TextLineReader()\n",
    "key, value = reader.read(filename_queue)\n",
    "\n",
    "record_defaults = [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]]\n",
    "xy = tf.decode_csv(value, record_defaults=record_defaults)\n",
    "\n",
    "train_x_batch, train_y_batch = tf.train.batch([xy[0:-1], xy[-1:]], batch_size=4)\n",
    "\n",
    "# graph\n",
    "X = tf.placeholder(tf.float32, shape=[None, 8])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([8, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1], name='bias'))\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(X,W) + b)\n",
    "\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "# session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "for step in range(2001):\n",
    "    x_batch, y_batch = sess.run([train_x_batch, train_y_batch])\n",
    "    cost_val,_ = sess.run([cost, train], feed_dict={X:x_batch, Y:y_batch})\n",
    "\n",
    "    if step % 200 == 0:\n",
    "        print(step, cost_val)\n",
    "    \n",
    "h, p, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X:train_x_batch, Y:train_y_batch})\n",
    "print(h,p,a)\n",
    "    \n",
    "coord.request_stop()\n",
    "coord.join(threads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow (GPU)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
